{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:27:45.806862Z",
     "iopub.status.busy": "2025-03-27T04:27:45.806482Z",
     "iopub.status.idle": "2025-03-27T04:27:45.811013Z",
     "shell.execute_reply": "2025-03-27T04:27:45.809995Z",
     "shell.execute_reply.started": "2025-03-27T04:27:45.806835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# MAIN_SEED = 1243\n",
    "# BATCH_SIZE = 16\n",
    "# hidden_dim = 64 # LSTM hidden size\n",
    "# output_dim = 19  # 19 classes (0-18 index)\n",
    "# num_layers = 2\n",
    "# LR = 0.00001\n",
    "# EPOCH = 30\n",
    "\n",
    "MAIN_SEED = 1000\n",
    "BATCH_SIZE = 20\n",
    "hidden_dim = 64 # LSTM hidden size\n",
    "output_dim = 19  # 19 classes (0-18 index)\n",
    "num_layers = 2\n",
    "LR = 0.00001\n",
    "EPOCH = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-27T04:27:45.812586Z",
     "iopub.status.busy": "2025-03-27T04:27:45.812328Z",
     "iopub.status.idle": "2025-03-27T04:27:45.825163Z",
     "shell.execute_reply": "2025-03-27T04:27:45.824512Z",
     "shell.execute_reply.started": "2025-03-27T04:27:45.812567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\김수빈\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    # Set seed for reproducibility\n",
    "    random.seed(seed_value)  # Python's random module\n",
    "    np.random.seed(seed_value)  # NumPy\n",
    "    torch.manual_seed(seed_value)  # PyTorch\n",
    "    torch.cuda.manual_seed(seed_value)  # GPU (if available)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # For multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic algorithms\n",
    "    torch.backends.cudnn.benchmark = False  # Disable benchmark mode for reproducibility\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed(MAIN_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:27:45.826876Z",
     "iopub.status.busy": "2025-03-27T04:27:45.826635Z",
     "iopub.status.idle": "2025-03-27T04:27:50.335807Z",
     "shell.execute_reply": "2025-03-27T04:27:50.334912Z",
     "shell.execute_reply.started": "2025-03-27T04:27:45.826858Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shape after split\n",
      "X_train: torch.Size([3466, 12, 19])\n",
      "y_train: torch.Size([3466, 19])\n",
      "X_val: torch.Size([241, 12, 19])\n",
      "y_val: torch.Size([241, 19])\n",
      "X_test: torch.Size([241, 12, 19])\n",
      "y_test: torch.Size([241, 19])\n",
      "\n",
      " Dataset:\n",
      "train: 174\n",
      "val: 13\n",
      "test: 13\n"
     ]
    }
   ],
   "source": [
    "# New: split before scaling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "sheet_url = \"final_train_data.csv\" # ternary output\n",
    "df = pd.read_csv(sheet_url)\n",
    "\n",
    "df_ret_original = df.iloc[:, 1:20]\n",
    "df_bm_original  = df.iloc[:, 61:80]\n",
    "\n",
    "df_ret = df.iloc[:, 1:20]\n",
    "df_out = df.iloc[:, 21:40]\n",
    "df_m = df.iloc[:, 41:60]\n",
    "df_bm = df.iloc[:, 61:80]\n",
    "df_b = df.iloc[:, 81:100]\n",
    "\n",
    "df_selected = df_m.copy() # which (combination of) indicator to use\n",
    "\n",
    "train_split_idx = math.floor(df_selected.shape[0] * 0.8)  # 80% for training\n",
    "val_split_idx = math.floor(df_selected.shape[0] * 0.9)   # 10% for validation\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "df_X_train, df_X_val, df_X_test = (\n",
    "    df_selected.iloc[:train_split_idx, :].copy(),               # Train set (0% -> 60%)\n",
    "    df_selected.iloc[train_split_idx:val_split_idx, :].copy(),  # Validation set (60% -> 80%)\n",
    "    df_selected.iloc[val_split_idx:, :].copy()                  # Test set (80% -> 100%)\n",
    ")\n",
    "\n",
    "df_y_train, df_y_val, df_y_test = (\n",
    "    df_out.iloc[:train_split_idx, :].copy(),\n",
    "    df_out.iloc[train_split_idx:val_split_idx, :].copy(),\n",
    "    df_out.iloc[val_split_idx:, :].copy()\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_X_train)\n",
    "X_val_scaled = scaler.transform(df_X_val)\n",
    "X_test_scaled = scaler.transform(df_X_test)\n",
    "\n",
    "\n",
    "def create_lstm_dataset(df, sequence_length=12, step=20):\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range((sequence_length - 1) * step, len(df)):  # Ensure enough past data for X\n",
    "        x_i = []\n",
    "        for j in range(sequence_length):\n",
    "            index = i - (sequence_length - 1 - j) * step  # Compute the index for each row in X_i\n",
    "            if index < 0:\n",
    "                break  # Stop if we run out of data\n",
    "            x_i.append(df[index, :19])  # Select return rates of stock1, stock2, stock3\n",
    "\n",
    "        if len(x_i) == sequence_length:  # Only append fully constructed sequences\n",
    "            X.append(np.array(x_i))\n",
    "            y.append(df[i, 19:])  # Take y from the same index as the last row of X_i\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "df_selected_aug_train = np.hstack([X_train_scaled, df_y_train])\n",
    "X_train, y_train = create_lstm_dataset(df_selected_aug_train)\n",
    "\n",
    "df_selected_aug_val = np.hstack([X_val_scaled, df_y_val])\n",
    "X_val, y_val = create_lstm_dataset(df_selected_aug_val)\n",
    "\n",
    "df_selected_aug_test = np.hstack([X_test_scaled, df_y_test])\n",
    "X_test, y_test = create_lstm_dataset(df_selected_aug_test)\n",
    "\n",
    "\n",
    "print(\"\\nData shape after split\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_val:\", y_val.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"\\n Dataset:\")\n",
    "print(\"train:\", len(train_dataloader))\n",
    "print(\"val:\", len(val_dataloader))\n",
    "print(\"test:\", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:27:50.337358Z",
     "iopub.status.busy": "2025-03-27T04:27:50.337051Z",
     "iopub.status.idle": "2025-03-27T04:27:50.342104Z",
     "shell.execute_reply": "2025-03-27T04:27:50.341279Z",
     "shell.execute_reply.started": "2025-03-27T04:27:50.337337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        # self.fc2 = nn.Linear(output_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)  # Softmax activation for multiclass classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Use last time step's output\n",
    "        # out = self.fc2(out)\n",
    "        return self.softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:27:50.343471Z",
     "iopub.status.busy": "2025-03-27T04:27:50.343136Z",
     "iopub.status.idle": "2025-03-27T04:28:15.460745Z",
     "shell.execute_reply": "2025-03-27T04:28:15.460023Z",
     "shell.execute_reply.started": "2025-03-27T04:27:50.343443Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 0.3055, Val Loss: 0.3054\n",
      "Epoch 2/33, Train Loss: 0.3054, Val Loss: 0.3054\n",
      "Epoch 3/33, Train Loss: 0.3054, Val Loss: 0.3054\n",
      "Epoch 4/33, Train Loss: 0.3054, Val Loss: 0.3054\n",
      "Epoch 5/33, Train Loss: 0.3054, Val Loss: 0.3054\n",
      "Epoch 6/33, Train Loss: 0.3053, Val Loss: 0.3054\n",
      "Epoch 7/33, Train Loss: 0.3053, Val Loss: 0.3053\n",
      "Epoch 8/33, Train Loss: 0.3053, Val Loss: 0.3053\n",
      "Epoch 9/33, Train Loss: 0.3052, Val Loss: 0.3053\n",
      "Epoch 10/33, Train Loss: 0.3052, Val Loss: 0.3053\n",
      "Epoch 11/33, Train Loss: 0.3051, Val Loss: 0.3053\n",
      "Epoch 12/33, Train Loss: 0.3051, Val Loss: 0.3053\n",
      "Epoch 13/33, Train Loss: 0.3050, Val Loss: 0.3052\n",
      "Epoch 14/33, Train Loss: 0.3050, Val Loss: 0.3052\n",
      "Epoch 15/33, Train Loss: 0.3049, Val Loss: 0.3052\n",
      "Epoch 16/33, Train Loss: 0.3048, Val Loss: 0.3052\n",
      "Epoch 17/33, Train Loss: 0.3047, Val Loss: 0.3051\n",
      "Epoch 18/33, Train Loss: 0.3046, Val Loss: 0.3051\n",
      "Epoch 19/33, Train Loss: 0.3045, Val Loss: 0.3051\n",
      "Epoch 20/33, Train Loss: 0.3045, Val Loss: 0.3051\n",
      "Epoch 21/33, Train Loss: 0.3044, Val Loss: 0.3050\n",
      "Epoch 22/33, Train Loss: 0.3043, Val Loss: 0.3050\n",
      "Epoch 23/33, Train Loss: 0.3042, Val Loss: 0.3050\n",
      "Epoch 24/33, Train Loss: 0.3042, Val Loss: 0.3050\n",
      "Epoch 25/33, Train Loss: 0.3041, Val Loss: 0.3050\n",
      "Epoch 26/33, Train Loss: 0.3041, Val Loss: 0.3050\n",
      "Epoch 27/33, Train Loss: 0.3040, Val Loss: 0.3049\n",
      "Epoch 28/33, Train Loss: 0.3040, Val Loss: 0.3049\n",
      "Epoch 29/33, Train Loss: 0.3039, Val Loss: 0.3049\n",
      "Epoch 30/33, Train Loss: 0.3038, Val Loss: 0.3049\n",
      "Epoch 31/33, Train Loss: 0.3038, Val Loss: 0.3049\n",
      "Epoch 32/33, Train Loss: 0.3037, Val Loss: 0.3049\n",
      "Epoch 33/33, Train Loss: 0.3036, Val Loss: 0.3048\n",
      "Model training complete and saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dim = df_selected.shape[1]  # Feature size\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Initialize Model, Loss, and Optimizer\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers)\n",
    "criterion = nn.MSELoss()  # Using MSELoss for direct comparison with one-hot vectors\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(EPOCH):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for inputs, labels_one_hot in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)  # Predicted probabilities (softmax output)\n",
    "        \n",
    "        loss = criterion(outputs, labels_one_hot)  # MSE loss between predicted and one-hot label\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCH}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"lstm_model.pth\")\n",
    "print(\"Model training complete and saved!\")\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, EPOCH + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(range(1, EPOCH + 1), val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss plot\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./loss_plot.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:28:15.462343Z",
     "iopub.status.busy": "2025-03-27T04:28:15.462100Z",
     "iopub.status.idle": "2025-03-27T04:28:15.488453Z",
     "shell.execute_reply": "2025-03-27T04:28:15.487842Z",
     "shell.execute_reply.started": "2025-03-27T04:28:15.462324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def transform_array(arr):\n",
    "    result = np.zeros_like(arr)  # Initialize an array filled with 0s\n",
    "\n",
    "    # Get indices of 4 largest and 4 smallest values in each row\n",
    "    sorted_indices = np.argsort(arr, axis=1)  # Sort indices along each row\n",
    "\n",
    "    lowest_indices = sorted_indices[:, :4]   # First 4 indices (smallest values)\n",
    "    highest_indices = sorted_indices[:, -4:] # Last 4 indices (largest values)\n",
    "\n",
    "    # Assign -1 to lowest values\n",
    "    np.put_along_axis(result, lowest_indices, -1, axis=1)\n",
    "    # Assign 1 to highest values\n",
    "    np.put_along_axis(result, highest_indices, 1, axis=1)\n",
    "    \n",
    "    return result\n",
    "output_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels_one_hot in test_dataloader:\n",
    "        outputs = model(inputs)  # Predicted probabilities (softmax output)\n",
    "        output_list.append(outputs.numpy())\n",
    "\n",
    "y_pred = np.vstack(output_list)\n",
    "y_pos_pred = transform_array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:28:15.489337Z",
     "iopub.status.busy": "2025-03-27T04:28:15.489109Z",
     "iopub.status.idle": "2025-03-27T04:28:15.548948Z",
     "shell.execute_reply": "2025-03-27T04:28:15.548314Z",
     "shell.execute_reply.started": "2025-03-27T04:28:15.489318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H4 strategy\n",
      "(Monthly)  Avg. Ret. = 0.015673106429460577\n",
      "(Annual) Avg. Ret. = 0.18807727715352693\n",
      "\n",
      "L4 strategy\n",
      "(Monthly)  Avg. Ret. = -0.00463820608713693\n",
      "(Annual) Avg. Ret. = -0.05565847304564316\n",
      "\n",
      "H4-L4 strategy\n",
      "(Monthly)  Avg. Ret. = 0.020311312516597506\n",
      "(Annual) Avg. Ret. = 0.24373575019917007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate H4 return\n",
    "df_ret_org_test = df_ret_original.iloc[220:,:].iloc[val_split_idx:, :]\n",
    "\n",
    "signals = pd.DataFrame(y_pos_pred).copy()\n",
    "signals.replace(-1, 0, inplace=True)\n",
    "\n",
    "signals.columns = df_ret_org_test.columns\n",
    "# print(signals.sum())\n",
    "\n",
    "signals.index = df_ret_org_test.index\n",
    "\n",
    "strategy_returns = (signals.shift(1) * df_ret_org_test)\n",
    "\n",
    "strategy_returns[\"Portfolio_sum\"] = strategy_returns.sum(axis=1)  # Aggregate portfolio returns\n",
    "strategy_returns[\"Portfolio\"] = strategy_returns[\"Portfolio_sum\"] / 4  # Aggregate portfolio returns\n",
    "strategy_returns[\"Cumulative Returns\"] = (1 + strategy_returns[\"Portfolio\"]).cumprod()\n",
    "\n",
    "print(\"H4 strategy\")\n",
    "print(\"(Monthly)  Avg. Ret. =\", strategy_returns[\"Portfolio\"].mean())\n",
    "print(\"(Annual) Avg. Ret. =\", 12 * strategy_returns[\"Portfolio\"].mean())\n",
    "print()\n",
    "\n",
    "# Export\n",
    "df_result = pd.concat([df_ret_org_test, signals, strategy_returns], axis=1)\n",
    "\n",
    "base_col_names = df_ret_org_test.columns.tolist()\n",
    "df_result.columns = base_col_names + \\\n",
    "                    [col[:-4] + \"_signal_pred\" for col in base_col_names] + \\\n",
    "                    [col[:-4] + \"_strat_ret\" for col in base_col_names] + \\\n",
    "                    [\"Portfolio_sum\", \"Portfolio\", \"Cumulative Returns\"]\n",
    "\n",
    "df_result.to_csv(\"result_test_ret_h4.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate L4 return\n",
    "df_ret_org_test = df_ret_original.iloc[220:,:].iloc[val_split_idx:, :]\n",
    "\n",
    "signals = pd.DataFrame(y_pos_pred).copy()\n",
    "signals.replace(1, 0, inplace=True)\n",
    "signals.replace(-1, 1, inplace=True)\n",
    "\n",
    "signals.columns = df_ret_org_test.columns\n",
    "# print(signals.sum())\n",
    "\n",
    "signals.index = df_ret_org_test.index\n",
    "\n",
    "strategy_returns = (signals.shift(1) * df_ret_org_test)\n",
    "\n",
    "strategy_returns[\"Portfolio_sum\"] = strategy_returns.sum(axis=1)  # Aggregate portfolio returns\n",
    "strategy_returns[\"Portfolio\"] = strategy_returns[\"Portfolio_sum\"] / 4  # Aggregate portfolio returns\n",
    "strategy_returns[\"Cumulative Returns\"] = (1 + strategy_returns[\"Portfolio\"]).cumprod()\n",
    "\n",
    "print(\"L4 strategy\")\n",
    "print(\"(Monthly)  Avg. Ret. =\", strategy_returns[\"Portfolio\"].mean())\n",
    "print(\"(Annual) Avg. Ret. =\", 12 * strategy_returns[\"Portfolio\"].mean())\n",
    "print()\n",
    "\n",
    "# Export\n",
    "df_result = pd.concat([df_ret_org_test, signals, strategy_returns], axis=1)\n",
    "\n",
    "base_col_names = df_ret_org_test.columns.tolist()\n",
    "df_result.columns = base_col_names + \\\n",
    "                    [col[:-4] + \"_signal_pred\" for col in base_col_names] + \\\n",
    "                    [col[:-4] + \"_strat_ret\" for col in base_col_names] + \\\n",
    "                    [\"Portfolio_sum\", \"Portfolio\", \"Cumulative Returns\"]\n",
    "\n",
    "df_result.to_csv(\"result_test_ret_l4.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate H4-L4 return\n",
    "df_ret_org_test = df_ret_original.iloc[220:,:].iloc[val_split_idx:, :]\n",
    "\n",
    "signals = pd.DataFrame(y_pos_pred).copy()\n",
    "\n",
    "signals.columns = df_ret_org_test.columns\n",
    "# print(signals.sum())\n",
    "\n",
    "signals.index = df_ret_org_test.index\n",
    "\n",
    "strategy_returns = (signals.shift(1) * df_ret_org_test)\n",
    "\n",
    "strategy_returns[\"Portfolio_sum\"] = strategy_returns.sum(axis=1)  # Aggregate portfolio returns\n",
    "strategy_returns[\"Portfolio\"] = strategy_returns[\"Portfolio_sum\"] / 4  # Aggregate portfolio returns\n",
    "strategy_returns[\"Cumulative Returns\"] = (1 + strategy_returns[\"Portfolio\"]).cumprod()\n",
    "\n",
    "print(\"H4-L4 strategy\")\n",
    "print(\"(Monthly)  Avg. Ret. =\", strategy_returns[\"Portfolio\"].mean())\n",
    "print(\"(Annual) Avg. Ret. =\", 12 * strategy_returns[\"Portfolio\"].mean())\n",
    "print()\n",
    "\n",
    "# Export\n",
    "df_result = pd.concat([df_ret_org_test, signals, strategy_returns], axis=1)\n",
    "\n",
    "base_col_names = df_ret_org_test.columns.tolist()\n",
    "df_result.columns = base_col_names + \\\n",
    "                    [col[:-4] + \"_signal_pred\" for col in base_col_names] + \\\n",
    "                    [col[:-4] + \"_strat_ret\" for col in base_col_names] + \\\n",
    "                    [\"Portfolio_sum\", \"Portfolio\", \"Cumulative Returns\"]\n",
    "\n",
    "df_result.to_csv(\"result_test_h4_l4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CL_ret</th>\n",
       "      <th>NG_ret</th>\n",
       "      <th>HO_ret</th>\n",
       "      <th>XB_ret</th>\n",
       "      <th>LP_ret</th>\n",
       "      <th>LA_ret</th>\n",
       "      <th>LN_ret</th>\n",
       "      <th>GC_ret</th>\n",
       "      <th>SI_ret</th>\n",
       "      <th>W_ret</th>\n",
       "      <th>C_ret</th>\n",
       "      <th>S_ret</th>\n",
       "      <th>LC_ret</th>\n",
       "      <th>LH_ret</th>\n",
       "      <th>SB_ret</th>\n",
       "      <th>CT_ret</th>\n",
       "      <th>CC_ret</th>\n",
       "      <th>KC_ret</th>\n",
       "      <th>JO_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.007443</td>\n",
       "      <td>-0.010101</td>\n",
       "      <td>-0.006546</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.021707</td>\n",
       "      <td>0.024280</td>\n",
       "      <td>-0.015118</td>\n",
       "      <td>-0.002872</td>\n",
       "      <td>-0.011849</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>-0.013490</td>\n",
       "      <td>-0.024397</td>\n",
       "      <td>0.120860</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>0.042245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.058577</td>\n",
       "      <td>0.127635</td>\n",
       "      <td>0.059533</td>\n",
       "      <td>0.056811</td>\n",
       "      <td>0.054561</td>\n",
       "      <td>0.058845</td>\n",
       "      <td>0.072603</td>\n",
       "      <td>0.035171</td>\n",
       "      <td>0.071047</td>\n",
       "      <td>0.079227</td>\n",
       "      <td>0.052405</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.062290</td>\n",
       "      <td>0.077412</td>\n",
       "      <td>0.056507</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>0.095282</td>\n",
       "      <td>0.079833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.158072</td>\n",
       "      <td>-0.354489</td>\n",
       "      <td>-0.149623</td>\n",
       "      <td>-0.161562</td>\n",
       "      <td>-0.118035</td>\n",
       "      <td>-0.127868</td>\n",
       "      <td>-0.205920</td>\n",
       "      <td>-0.058571</td>\n",
       "      <td>-0.131231</td>\n",
       "      <td>-0.222068</td>\n",
       "      <td>-0.157497</td>\n",
       "      <td>-0.109310</td>\n",
       "      <td>-0.068152</td>\n",
       "      <td>-0.201769</td>\n",
       "      <td>-0.138149</td>\n",
       "      <td>-0.151586</td>\n",
       "      <td>-0.358869</td>\n",
       "      <td>-0.170377</td>\n",
       "      <td>-0.106312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.035473</td>\n",
       "      <td>-0.078410</td>\n",
       "      <td>-0.050436</td>\n",
       "      <td>-0.040016</td>\n",
       "      <td>-0.036929</td>\n",
       "      <td>-0.024389</td>\n",
       "      <td>-0.049830</td>\n",
       "      <td>-0.004595</td>\n",
       "      <td>-0.028555</td>\n",
       "      <td>-0.059081</td>\n",
       "      <td>-0.032961</td>\n",
       "      <td>-0.051493</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>-0.033107</td>\n",
       "      <td>-0.064417</td>\n",
       "      <td>-0.056034</td>\n",
       "      <td>-0.023339</td>\n",
       "      <td>-0.008874</td>\n",
       "      <td>-0.010953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.007675</td>\n",
       "      <td>-0.008970</td>\n",
       "      <td>-0.010734</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>-0.015457</td>\n",
       "      <td>0.023617</td>\n",
       "      <td>0.024505</td>\n",
       "      <td>-0.024590</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>-0.014035</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.018483</td>\n",
       "      <td>-0.029224</td>\n",
       "      <td>-0.029403</td>\n",
       "      <td>0.063809</td>\n",
       "      <td>0.046133</td>\n",
       "      <td>0.024258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.046238</td>\n",
       "      <td>0.065442</td>\n",
       "      <td>0.027627</td>\n",
       "      <td>0.042136</td>\n",
       "      <td>0.043373</td>\n",
       "      <td>0.045198</td>\n",
       "      <td>0.049268</td>\n",
       "      <td>0.048461</td>\n",
       "      <td>0.077910</td>\n",
       "      <td>0.034096</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>0.027651</td>\n",
       "      <td>0.030984</td>\n",
       "      <td>0.055639</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.298912</td>\n",
       "      <td>0.106293</td>\n",
       "      <td>0.075232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.141168</td>\n",
       "      <td>0.370601</td>\n",
       "      <td>0.155627</td>\n",
       "      <td>0.135918</td>\n",
       "      <td>0.139266</td>\n",
       "      <td>0.171267</td>\n",
       "      <td>0.148454</td>\n",
       "      <td>0.101514</td>\n",
       "      <td>0.208186</td>\n",
       "      <td>0.210573</td>\n",
       "      <td>0.111741</td>\n",
       "      <td>0.104242</td>\n",
       "      <td>0.092862</td>\n",
       "      <td>0.222939</td>\n",
       "      <td>0.251513</td>\n",
       "      <td>0.174529</td>\n",
       "      <td>0.642142</td>\n",
       "      <td>0.354548</td>\n",
       "      <td>0.324093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CL_ret      NG_ret      HO_ret      XB_ret      LP_ret      LA_ret  \\\n",
       "count  241.000000  241.000000  241.000000  241.000000  241.000000  241.000000   \n",
       "mean     0.007443   -0.010101   -0.006546    0.001896    0.003898    0.010244   \n",
       "std      0.058577    0.127635    0.059533    0.056811    0.054561    0.058845   \n",
       "min     -0.158072   -0.354489   -0.149623   -0.161562   -0.118035   -0.127868   \n",
       "25%     -0.035473   -0.078410   -0.050436   -0.040016   -0.036929   -0.024389   \n",
       "50%      0.007675   -0.008970   -0.010734    0.002953    0.003101    0.007113   \n",
       "75%      0.046238    0.065442    0.027627    0.042136    0.043373    0.045198   \n",
       "max      0.141168    0.370601    0.155627    0.135918    0.139266    0.171267   \n",
       "\n",
       "           LN_ret      GC_ret      SI_ret       W_ret       C_ret       S_ret  \\\n",
       "count  241.000000  241.000000  241.000000  241.000000  241.000000  241.000000   \n",
       "mean    -0.005496    0.021707    0.024280   -0.015118   -0.002872   -0.011849   \n",
       "std      0.072603    0.035171    0.071047    0.079227    0.052405    0.046864   \n",
       "min     -0.205920   -0.058571   -0.131231   -0.222068   -0.157497   -0.109310   \n",
       "25%     -0.049830   -0.004595   -0.028555   -0.059081   -0.032961   -0.051493   \n",
       "50%     -0.015457    0.023617    0.024505   -0.024590    0.005233   -0.014035   \n",
       "75%      0.049268    0.048461    0.077910    0.034096    0.032778    0.027651   \n",
       "max      0.148454    0.101514    0.208186    0.210573    0.111741    0.104242   \n",
       "\n",
       "           LC_ret      LH_ret      SB_ret      CT_ret      CC_ret      KC_ret  \\\n",
       "count  241.000000  241.000000  241.000000  241.000000  241.000000  241.000000   \n",
       "mean     0.009655    0.008404   -0.013490   -0.024397    0.120860    0.056816   \n",
       "std      0.031532    0.062290    0.077412    0.056507    0.217642    0.095282   \n",
       "min     -0.068152   -0.201769   -0.138149   -0.151586   -0.358869   -0.170377   \n",
       "25%     -0.011393   -0.033107   -0.064417   -0.056034   -0.023339   -0.008874   \n",
       "50%      0.013420    0.018483   -0.029224   -0.029403    0.063809    0.046133   \n",
       "75%      0.030984    0.055639    0.016595    0.001392    0.298912    0.106293   \n",
       "max      0.092862    0.222939    0.251513    0.174529    0.642142    0.354548   \n",
       "\n",
       "           JO_ret  \n",
       "count  241.000000  \n",
       "mean     0.042245  \n",
       "std      0.079833  \n",
       "min     -0.106312  \n",
       "25%     -0.010953  \n",
       "50%      0.024258  \n",
       "75%      0.075232  \n",
       "max      0.324093  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ret_org_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO\n",
    "# # LSTM Grid Search on Commodity Return Data (Colab Compatible)\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # CSV 업로드 후 실행\n",
    "# df = pd.read_csv(\"final_train_data.csv\")\n",
    "# df_ret_original = df.iloc[:, 1:20]\n",
    "# df_out = df.iloc[:, 21:40]\n",
    "# df_m = df.iloc[:, 41:60]\n",
    "# df_selected = df_m.copy()\n",
    "\n",
    "# train_split_idx = int(df_selected.shape[0] * 0.8)\n",
    "# val_split_idx = int(df_selected.shape[0] * 0.9)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(df_selected.iloc[:train_split_idx])\n",
    "# X_test_scaled = scaler.transform(df_selected.iloc[val_split_idx:])\n",
    "# df_y_train = df_out.iloc[:train_split_idx]\n",
    "# df_y_test = df_out.iloc[val_split_idx:]\n",
    "\n",
    "# def create_lstm_dataset(df, sequence_length=12, step=20):\n",
    "#     X, y = [], []\n",
    "#     for i in range((sequence_length - 1) * step, len(df)):\n",
    "#         x_i = []\n",
    "#         for j in range(sequence_length):\n",
    "#             index = i - (sequence_length - 1 - j) * step\n",
    "#             if index < 0:\n",
    "#                 break\n",
    "#             x_i.append(df[index, :19])\n",
    "#         if len(x_i) == sequence_length:\n",
    "#             X.append(np.array(x_i))\n",
    "#             y.append(df[i, 19:])\n",
    "#     return torch.tensor(np.array(X), dtype=torch.float32), torch.tensor(np.array(y), dtype=torch.float32)\n",
    "\n",
    "# df_selected_aug_train = np.hstack([X_train_scaled, df_y_train])\n",
    "# df_selected_aug_test = np.hstack([X_test_scaled, df_y_test])\n",
    "# X_train, y_train = create_lstm_dataset(df_selected_aug_train)\n",
    "# X_test, y_test = create_lstm_dataset(df_selected_aug_test)\n",
    "# df_ret_org_test = df_ret_original.iloc[220:,:].iloc[val_split_idx:, :]\n",
    "\n",
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "#         super(LSTMModel, self).__init__()\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "#     def forward(self, x):\n",
    "#         lstm_out, _ = self.lstm(x)\n",
    "#         out = self.fc(lstm_out[:, -1, :])\n",
    "#         return self.softmax(out)\n",
    "\n",
    "# def transform_array(arr):\n",
    "#     result = np.zeros_like(arr)\n",
    "#     sorted_indices = np.argsort(arr, axis=1)\n",
    "#     lowest_indices = sorted_indices[:, :4]\n",
    "#     highest_indices = sorted_indices[:, -4:]\n",
    "#     np.put_along_axis(result, lowest_indices, -1, axis=1)\n",
    "#     np.put_along_axis(result, highest_indices, 1, axis=1)\n",
    "#     return result\n",
    "\n",
    "# # 실험 조합\n",
    "# # param_grid = [(16, 30), (32, 30)]  # 필요시 확장 가능\n",
    "# # results = []\n",
    "# import itertools\n",
    "\n",
    "# batch_sizes = [16, 18, 20, 24, 32]\n",
    "# epochs = [30, 32, 33, 35]\n",
    "# param_grid = list(itertools.product(batch_sizes, epochs))  # 전체 조합 생성\n",
    "# results = []\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# for batch_size, epoch in param_grid:\n",
    "#     torch.manual_seed(1243)\n",
    "#     model = LSTMModel(input_dim=df_selected.shape[1], hidden_dim=64, output_dim=19, num_layers=2).to(device)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "#     train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     for ep in range(epoch):\n",
    "#         model.train()\n",
    "#         for inputs, labels in train_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#     model.eval()\n",
    "#     output_list = []\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, _ in DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size):\n",
    "#             inputs = inputs.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             output_list.append(outputs.cpu().numpy())\n",
    "\n",
    "#     y_pred = np.vstack(output_list)\n",
    "#     y_pos_pred = transform_array(y_pred)\n",
    "#     signals = pd.DataFrame(y_pos_pred)\n",
    "#     signals.columns = df_ret_org_test.columns\n",
    "#     signals.index = df_ret_org_test.index\n",
    "\n",
    "#     strat_returns = (signals.shift(1) * df_ret_org_test)\n",
    "#     strat_returns[\"Portfolio\"] = strat_returns.sum(axis=1) / 4\n",
    "#     monthly_ret = strat_returns[\"Portfolio\"].mean()\n",
    "#     annual_ret = monthly_ret * 12\n",
    "\n",
    "#     results.append({\n",
    "#         \"BATCH_SIZE\": batch_size,\n",
    "#         \"EPOCH\": epoch,\n",
    "#         \"Monthly\": round(monthly_ret, 6),\n",
    "#         \"Annual\": round(annual_ret, 6)\n",
    "#     })\n",
    "\n",
    "# # 결과 출력\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=2\n",
      "\n",
      "Extended Grid Search Results:\n",
      "    BATCH_SIZE  EPOCH  hidden_dim       LR  num_layers   Monthly    Annual\n",
      "12          16     33         128  0.00001           1  0.040603  0.487238\n",
      "4           16     30         128  0.00001           1  0.039196  0.470346\n",
      "28          20     33         128  0.00001           1  0.037797  0.453562\n",
      "20          20     30         128  0.00001           1  0.036590  0.439078\n",
      "21          20     30         128  0.00001           2  0.035592  0.427101\n",
      "29          20     33         128  0.00001           2  0.034159  0.409908\n",
      "5           16     30         128  0.00001           2  0.032948  0.395379\n",
      "9           16     33          64  0.00001           2  0.029941  0.359296\n",
      "1           16     30          64  0.00001           2  0.028413  0.340960\n",
      "25          20     33          64  0.00001           2  0.027245  0.326940\n",
      "8           16     33          64  0.00001           1  0.026151  0.313809\n",
      "0           16     30          64  0.00001           1  0.025082  0.300983\n",
      "24          20     33          64  0.00001           1  0.024575  0.294905\n",
      "27          20     33          64  0.00010           2  0.023449  0.281387\n",
      "18          20     30          64  0.00010           1  0.022463  0.269556\n",
      "19          20     30          64  0.00010           2  0.022272  0.267267\n",
      "16          20     30          64  0.00001           1  0.021659  0.259908\n",
      "13          16     33         128  0.00001           2  0.020375  0.244503\n",
      "17          20     30          64  0.00001           2  0.019606  0.235271\n",
      "10          16     33          64  0.00010           1  0.018023  0.216274\n",
      "26          20     33          64  0.00010           1  0.016873  0.202475\n",
      "2           16     30          64  0.00010           1  0.016371  0.196454\n",
      "3           16     30          64  0.00010           2  0.016168  0.194012\n",
      "22          20     30         128  0.00010           1  0.013693  0.164314\n",
      "11          16     33          64  0.00010           2  0.012911  0.154931\n",
      "30          20     33         128  0.00010           1  0.011381  0.136570\n",
      "14          16     33         128  0.00010           1  0.009863  0.118360\n",
      "6           16     30         128  0.00010           1  0.009845  0.118139\n",
      "23          20     30         128  0.00010           2  0.007790  0.093483\n",
      "31          20     33         128  0.00010           2  0.005980  0.071765\n",
      "7           16     30         128  0.00010           2  0.001585  0.019019\n",
      "15          16     33         128  0.00010           2 -0.002773 -0.033281\n"
     ]
    }
   ],
   "source": [
    "# LSTM Grid Search (Extended: all hyperparameters tunable)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import itertools\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Set seed function\n",
    "# -----------------------------\n",
    "MAIN_SEED = 999\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load and preprocess data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"final_train_data.csv\")\n",
    "df_ret_original = df.iloc[:, 1:20]\n",
    "df_out = df.iloc[:, 21:40]\n",
    "df_m = df.iloc[:, 41:60]\n",
    "df_selected = df_m.copy()\n",
    "\n",
    "train_split_idx = int(df_selected.shape[0] * 0.8)\n",
    "val_split_idx = int(df_selected.shape[0] * 0.9)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_selected.iloc[:train_split_idx])\n",
    "X_test_scaled = scaler.transform(df_selected.iloc[val_split_idx:])\n",
    "df_y_train = df_out.iloc[:train_split_idx]\n",
    "df_y_test = df_out.iloc[val_split_idx:]\n",
    "\n",
    "def create_lstm_dataset(df, sequence_length=12, step=20):\n",
    "    X, y = [], []\n",
    "    for i in range((sequence_length - 1) * step, len(df)):\n",
    "        x_i = []\n",
    "        for j in range(sequence_length):\n",
    "            index = i - (sequence_length - 1 - j) * step\n",
    "            if index < 0:\n",
    "                break\n",
    "            x_i.append(df[index, :19])\n",
    "        if len(x_i) == sequence_length:\n",
    "            X.append(np.array(x_i))\n",
    "            y.append(df[i, 19:])\n",
    "    return torch.tensor(np.array(X), dtype=torch.float32), torch.tensor(np.array(y), dtype=torch.float32)\n",
    "\n",
    "df_selected_aug_train = np.hstack([X_train_scaled, df_y_train])\n",
    "df_selected_aug_test = np.hstack([X_test_scaled, df_y_test])\n",
    "X_train, y_train = create_lstm_dataset(df_selected_aug_train)\n",
    "X_test, y_test = create_lstm_dataset(df_selected_aug_test)\n",
    "df_ret_org_test = df_ret_original.iloc[220:, :].iloc[val_split_idx:, :]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. LSTM model definition\n",
    "# -----------------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return self.softmax(out)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Transformation for top/bottom 4\n",
    "# -----------------------------\n",
    "def transform_array(arr):\n",
    "    result = np.zeros_like(arr)\n",
    "    sorted_indices = np.argsort(arr, axis=1)\n",
    "    lowest_indices = sorted_indices[:, :4]\n",
    "    highest_indices = sorted_indices[:, -4:]\n",
    "    np.put_along_axis(result, lowest_indices, -1, axis=1)\n",
    "    np.put_along_axis(result, highest_indices, 1, axis=1)\n",
    "    return result\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Extended Grid Search\n",
    "# -----------------------------\n",
    "batch_sizes = [16, 20]\n",
    "epochs = [30, 33]\n",
    "hidden_dims = [64, 128]\n",
    "learning_rates = [0.00001, 0.0001]\n",
    "num_layers_list = [1, 2]\n",
    "\n",
    "param_grid = list(itertools.product(batch_sizes, epochs, hidden_dims, learning_rates, num_layers_list))\n",
    "\n",
    "results = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for batch_size, epoch, hidden_dim, lr, num_layers in param_grid:\n",
    "    print(f\"Running BS={batch_size}, EP={epoch}, HD={hidden_dim}, LR={lr}, NL={num_layers}\")\n",
    "    set_seed(MAIN_SEED)\n",
    "\n",
    "    model = LSTMModel(input_dim=df_selected.shape[1], hidden_dim=hidden_dim, output_dim=19, num_layers=num_layers).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            output_list.append(outputs.cpu().numpy())\n",
    "\n",
    "    y_pred = np.vstack(output_list)\n",
    "    y_pos_pred = transform_array(y_pred)\n",
    "    signals = pd.DataFrame(y_pos_pred)\n",
    "    signals.columns = df_ret_org_test.columns\n",
    "    signals.index = df_ret_org_test.index\n",
    "\n",
    "    strat_returns = (signals.shift(1) * df_ret_org_test)\n",
    "    strat_returns[\"Portfolio\"] = strat_returns.sum(axis=1) / 4\n",
    "    monthly_ret = strat_returns[\"Portfolio\"].mean()\n",
    "    annual_ret = monthly_ret * 12\n",
    "\n",
    "    results.append({\n",
    "        \"BATCH_SIZE\": batch_size,\n",
    "        \"EPOCH\": epoch,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"LR\": lr,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"Monthly\": round(monthly_ret, 6),\n",
    "        \"Annual\": round(annual_ret, 6)\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Save and print results\n",
    "# -----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nExtended Grid Search Results:\")\n",
    "print(results_df.sort_values(by=\"Annual\", ascending=False))\n",
    "results_df.to_csv(\"extended_grid_search_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=2\n",
      "\n",
      "Extended Grid Search Results:\n",
      "    BATCH_SIZE  EPOCH  hidden_dim       LR  num_layers   Monthly    Annual\n",
      "8           16     33          64  0.00001           1  0.029674  0.356089\n",
      "0           16     30          64  0.00001           1  0.028680  0.344162\n",
      "24          20     33          64  0.00001           1  0.027879  0.334553\n",
      "16          20     30          64  0.00001           1  0.025646  0.307751\n",
      "20          20     30         128  0.00001           1  0.018374  0.220488\n",
      "28          20     33         128  0.00001           1  0.017323  0.207877\n",
      "4           16     30         128  0.00001           1  0.017258  0.207091\n",
      "6           16     30         128  0.00010           1  0.016269  0.195230\n",
      "22          20     30         128  0.00010           1  0.016175  0.194104\n",
      "14          16     33         128  0.00010           1  0.015637  0.187643\n",
      "12          16     33         128  0.00001           1  0.014937  0.179249\n",
      "30          20     33         128  0.00010           1  0.014626  0.175509\n",
      "18          20     30          64  0.00010           1  0.010066  0.120789\n",
      "2           16     30          64  0.00010           1  0.007901  0.094810\n",
      "26          20     33          64  0.00010           1  0.007805  0.093656\n",
      "3           16     30          64  0.00010           2  0.006206  0.074468\n",
      "11          16     33          64  0.00010           2  0.005629  0.067549\n",
      "19          20     30          64  0.00010           2  0.005446  0.065347\n",
      "27          20     33          64  0.00010           2  0.004826  0.057907\n",
      "10          16     33          64  0.00010           1  0.004744  0.056933\n",
      "1           16     30          64  0.00001           2  0.002745  0.032943\n",
      "25          20     33          64  0.00001           2  0.000146  0.001749\n",
      "13          16     33         128  0.00001           2 -0.002677 -0.032124\n",
      "29          20     33         128  0.00001           2 -0.002777 -0.033327\n",
      "21          20     30         128  0.00001           2 -0.003084 -0.037008\n",
      "5           16     30         128  0.00001           2 -0.003155 -0.037863\n",
      "9           16     33          64  0.00001           2 -0.003598 -0.043175\n",
      "17          20     30          64  0.00001           2 -0.003994 -0.047928\n",
      "7           16     30         128  0.00010           2 -0.019368 -0.232416\n",
      "15          16     33         128  0.00010           2 -0.024051 -0.288608\n",
      "23          20     30         128  0.00010           2 -0.027587 -0.331047\n",
      "31          20     33         128  0.00010           2 -0.031782 -0.381384\n"
     ]
    }
   ],
   "source": [
    "# LSTM Grid Search (Extended: all hyperparameters tunable)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import itertools\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Set seed function\n",
    "# -----------------------------\n",
    "MAIN_SEED = 1342\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load and preprocess data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"final_train_data.csv\")\n",
    "df_ret_original = df.iloc[:, 1:20]\n",
    "df_out = df.iloc[:, 21:40]\n",
    "df_m = df.iloc[:, 41:60]\n",
    "df_selected = df_m.copy()\n",
    "\n",
    "train_split_idx = int(df_selected.shape[0] * 0.8)\n",
    "val_split_idx = int(df_selected.shape[0] * 0.9)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_selected.iloc[:train_split_idx])\n",
    "X_test_scaled = scaler.transform(df_selected.iloc[val_split_idx:])\n",
    "df_y_train = df_out.iloc[:train_split_idx]\n",
    "df_y_test = df_out.iloc[val_split_idx:]\n",
    "\n",
    "def create_lstm_dataset(df, sequence_length=12, step=20):\n",
    "    X, y = [], []\n",
    "    for i in range((sequence_length - 1) * step, len(df)):\n",
    "        x_i = []\n",
    "        for j in range(sequence_length):\n",
    "            index = i - (sequence_length - 1 - j) * step\n",
    "            if index < 0:\n",
    "                break\n",
    "            x_i.append(df[index, :19])\n",
    "        if len(x_i) == sequence_length:\n",
    "            X.append(np.array(x_i))\n",
    "            y.append(df[i, 19:])\n",
    "    return torch.tensor(np.array(X), dtype=torch.float32), torch.tensor(np.array(y), dtype=torch.float32)\n",
    "\n",
    "df_selected_aug_train = np.hstack([X_train_scaled, df_y_train])\n",
    "df_selected_aug_test = np.hstack([X_test_scaled, df_y_test])\n",
    "X_train, y_train = create_lstm_dataset(df_selected_aug_train)\n",
    "X_test, y_test = create_lstm_dataset(df_selected_aug_test)\n",
    "df_ret_org_test = df_ret_original.iloc[220:, :].iloc[val_split_idx:, :]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. LSTM model definition\n",
    "# -----------------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return self.softmax(out)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Transformation for top/bottom 4\n",
    "# -----------------------------\n",
    "def transform_array(arr):\n",
    "    result = np.zeros_like(arr)\n",
    "    sorted_indices = np.argsort(arr, axis=1)\n",
    "    lowest_indices = sorted_indices[:, :4]\n",
    "    highest_indices = sorted_indices[:, -4:]\n",
    "    np.put_along_axis(result, lowest_indices, -1, axis=1)\n",
    "    np.put_along_axis(result, highest_indices, 1, axis=1)\n",
    "    return result\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Extended Grid Search\n",
    "# -----------------------------\n",
    "batch_sizes = [16, 20]\n",
    "epochs = [30, 33]\n",
    "hidden_dims = [64, 128]\n",
    "learning_rates = [0.00001, 0.0001]\n",
    "num_layers_list = [1, 2]\n",
    "\n",
    "param_grid = list(itertools.product(batch_sizes, epochs, hidden_dims, learning_rates, num_layers_list))\n",
    "\n",
    "results = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for batch_size, epoch, hidden_dim, lr, num_layers in param_grid:\n",
    "    print(f\"Running BS={batch_size}, EP={epoch}, HD={hidden_dim}, LR={lr}, NL={num_layers}\")\n",
    "    set_seed(MAIN_SEED)\n",
    "\n",
    "    model = LSTMModel(input_dim=df_selected.shape[1], hidden_dim=hidden_dim, output_dim=19, num_layers=num_layers).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            output_list.append(outputs.cpu().numpy())\n",
    "\n",
    "    y_pred = np.vstack(output_list)\n",
    "    y_pos_pred = transform_array(y_pred)\n",
    "    signals = pd.DataFrame(y_pos_pred)\n",
    "    signals.columns = df_ret_org_test.columns\n",
    "    signals.index = df_ret_org_test.index\n",
    "\n",
    "    strat_returns = (signals.shift(1) * df_ret_org_test)\n",
    "    strat_returns[\"Portfolio\"] = strat_returns.sum(axis=1) / 4\n",
    "    monthly_ret = strat_returns[\"Portfolio\"].mean()\n",
    "    annual_ret = monthly_ret * 12\n",
    "\n",
    "    results.append({\n",
    "        \"BATCH_SIZE\": batch_size,\n",
    "        \"EPOCH\": epoch,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"LR\": lr,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"Monthly\": round(monthly_ret, 6),\n",
    "        \"Annual\": round(annual_ret, 6)\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Save and print results\n",
    "# -----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nExtended Grid Search Results:\")\n",
    "print(results_df.sort_values(by=\"Annual\", ascending=False))\n",
    "results_df.to_csv(\"extended_grid_search_results1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=2\n",
      "\n",
      "Extended Grid Search Results:\n",
      "    BATCH_SIZE  EPOCH  hidden_dim       LR  num_layers   Monthly    Annual\n",
      "4           16     30         128  0.00001           1  0.050379  0.604547\n",
      "28          20     33         128  0.00001           1  0.049998  0.599974\n",
      "12          16     33         128  0.00001           1  0.049840  0.598079\n",
      "20          20     30         128  0.00001           1  0.047895  0.574742\n",
      "1           16     30          64  0.00001           2  0.042904  0.514846\n",
      "25          20     33          64  0.00001           2  0.042842  0.514099\n",
      "9           16     33          64  0.00001           2  0.042179  0.506148\n",
      "17          20     30          64  0.00001           2  0.035713  0.428553\n",
      "26          20     33          64  0.00010           1  0.032893  0.394721\n",
      "18          20     30          64  0.00010           1  0.031322  0.375863\n",
      "10          16     33          64  0.00010           1  0.029931  0.359167\n",
      "2           16     30          64  0.00010           1  0.027672  0.332070\n",
      "16          20     30          64  0.00001           1  0.019186  0.230233\n",
      "24          20     33          64  0.00001           1  0.017886  0.214632\n",
      "0           16     30          64  0.00001           1  0.017183  0.206191\n",
      "8           16     33          64  0.00001           1  0.016939  0.203264\n",
      "21          20     30         128  0.00001           2  0.013930  0.167165\n",
      "29          20     33         128  0.00001           2  0.007406  0.088869\n",
      "5           16     30         128  0.00001           2  0.006393  0.076710\n",
      "13          16     33         128  0.00001           2  0.001053  0.012637\n",
      "30          20     33         128  0.00010           1 -0.000575 -0.006903\n",
      "22          20     30         128  0.00010           1 -0.001244 -0.014928\n",
      "6           16     30         128  0.00010           1 -0.002167 -0.026009\n",
      "14          16     33         128  0.00010           1 -0.003126 -0.037512\n",
      "19          20     30          64  0.00010           2 -0.005284 -0.063410\n",
      "27          20     33          64  0.00010           2 -0.007742 -0.092899\n",
      "3           16     30          64  0.00010           2 -0.012011 -0.144127\n",
      "23          20     30         128  0.00010           2 -0.016535 -0.198414\n",
      "11          16     33          64  0.00010           2 -0.016613 -0.199362\n",
      "7           16     30         128  0.00010           2 -0.020152 -0.241826\n",
      "31          20     33         128  0.00010           2 -0.021043 -0.252514\n",
      "15          16     33         128  0.00010           2 -0.023602 -0.283227\n"
     ]
    }
   ],
   "source": [
    "# LSTM Grid Search (Extended: all hyperparameters tunable)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import itertools\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Set seed function\n",
    "# -----------------------------\n",
    "MAIN_SEED = 2000\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load and preprocess data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"final_train_data.csv\")\n",
    "df_ret_original = df.iloc[:, 1:20]\n",
    "df_out = df.iloc[:, 21:40]\n",
    "df_m = df.iloc[:, 41:60]\n",
    "df_selected = df_m.copy()\n",
    "\n",
    "train_split_idx = int(df_selected.shape[0] * 0.8)\n",
    "val_split_idx = int(df_selected.shape[0] * 0.9)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_selected.iloc[:train_split_idx])\n",
    "X_test_scaled = scaler.transform(df_selected.iloc[val_split_idx:])\n",
    "df_y_train = df_out.iloc[:train_split_idx]\n",
    "df_y_test = df_out.iloc[val_split_idx:]\n",
    "\n",
    "def create_lstm_dataset(df, sequence_length=12, step=20):\n",
    "    X, y = [], []\n",
    "    for i in range((sequence_length - 1) * step, len(df)):\n",
    "        x_i = []\n",
    "        for j in range(sequence_length):\n",
    "            index = i - (sequence_length - 1 - j) * step\n",
    "            if index < 0:\n",
    "                break\n",
    "            x_i.append(df[index, :19])\n",
    "        if len(x_i) == sequence_length:\n",
    "            X.append(np.array(x_i))\n",
    "            y.append(df[i, 19:])\n",
    "    return torch.tensor(np.array(X), dtype=torch.float32), torch.tensor(np.array(y), dtype=torch.float32)\n",
    "\n",
    "df_selected_aug_train = np.hstack([X_train_scaled, df_y_train])\n",
    "df_selected_aug_test = np.hstack([X_test_scaled, df_y_test])\n",
    "X_train, y_train = create_lstm_dataset(df_selected_aug_train)\n",
    "X_test, y_test = create_lstm_dataset(df_selected_aug_test)\n",
    "df_ret_org_test = df_ret_original.iloc[220:, :].iloc[val_split_idx:, :]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. LSTM model definition\n",
    "# -----------------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return self.softmax(out)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Transformation for top/bottom 4\n",
    "# -----------------------------\n",
    "def transform_array(arr):\n",
    "    result = np.zeros_like(arr)\n",
    "    sorted_indices = np.argsort(arr, axis=1)\n",
    "    lowest_indices = sorted_indices[:, :4]\n",
    "    highest_indices = sorted_indices[:, -4:]\n",
    "    np.put_along_axis(result, lowest_indices, -1, axis=1)\n",
    "    np.put_along_axis(result, highest_indices, 1, axis=1)\n",
    "    return result\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Extended Grid Search\n",
    "# -----------------------------\n",
    "batch_sizes = [16, 20]\n",
    "epochs = [30, 33]\n",
    "hidden_dims = [64, 128]\n",
    "learning_rates = [0.00001, 0.0001]\n",
    "num_layers_list = [1, 2]\n",
    "\n",
    "param_grid = list(itertools.product(batch_sizes, epochs, hidden_dims, learning_rates, num_layers_list))\n",
    "\n",
    "results = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for batch_size, epoch, hidden_dim, lr, num_layers in param_grid:\n",
    "    print(f\"Running BS={batch_size}, EP={epoch}, HD={hidden_dim}, LR={lr}, NL={num_layers}\")\n",
    "    set_seed(MAIN_SEED)\n",
    "\n",
    "    model = LSTMModel(input_dim=df_selected.shape[1], hidden_dim=hidden_dim, output_dim=19, num_layers=num_layers).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            output_list.append(outputs.cpu().numpy())\n",
    "\n",
    "    y_pred = np.vstack(output_list)\n",
    "    y_pos_pred = transform_array(y_pred)\n",
    "    signals = pd.DataFrame(y_pos_pred)\n",
    "    signals.columns = df_ret_org_test.columns\n",
    "    signals.index = df_ret_org_test.index\n",
    "\n",
    "    strat_returns = (signals.shift(1) * df_ret_org_test)\n",
    "    strat_returns[\"Portfolio\"] = strat_returns.sum(axis=1) / 4\n",
    "    monthly_ret = strat_returns[\"Portfolio\"].mean()\n",
    "    annual_ret = monthly_ret * 12\n",
    "\n",
    "    results.append({\n",
    "        \"BATCH_SIZE\": batch_size,\n",
    "        \"EPOCH\": epoch,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"LR\": lr,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"Monthly\": round(monthly_ret, 6),\n",
    "        \"Annual\": round(annual_ret, 6)\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Save and print results\n",
    "# -----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nExtended Grid Search Results:\")\n",
    "print(results_df.sort_values(by=\"Annual\", ascending=False))\n",
    "results_df.to_csv(\"extended_grid_search_results2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=2\n",
      "\n",
      "Extended Grid Search Results:\n",
      "    BATCH_SIZE  EPOCH  hidden_dim       LR  num_layers   Monthly    Annual\n",
      "30          20     33         128  0.00010           1  0.015019  0.180231\n",
      "22          20     30         128  0.00010           1  0.014962  0.179549\n",
      "18          20     30          64  0.00010           1  0.014352  0.172219\n",
      "14          16     33         128  0.00010           1  0.013866  0.166397\n",
      "2           16     30          64  0.00010           1  0.013448  0.161374\n",
      "6           16     30         128  0.00010           1  0.013285  0.159426\n",
      "10          16     33          64  0.00010           1  0.012990  0.155878\n",
      "26          20     33          64  0.00010           1  0.012896  0.154749\n",
      "20          20     30         128  0.00001           1  0.011877  0.142518\n",
      "28          20     33         128  0.00001           1  0.011590  0.139079\n",
      "4           16     30         128  0.00001           1  0.011559  0.138703\n",
      "12          16     33         128  0.00001           1  0.011254  0.135047\n",
      "5           16     30         128  0.00001           2  0.002973  0.035671\n",
      "21          20     30         128  0.00001           2  0.002931  0.035171\n",
      "29          20     33         128  0.00001           2  0.002785  0.033420\n",
      "13          16     33         128  0.00001           2 -0.001555 -0.018659\n",
      "7           16     30         128  0.00010           2 -0.008368 -0.100415\n",
      "23          20     30         128  0.00010           2 -0.008530 -0.102357\n",
      "15          16     33         128  0.00010           2 -0.009486 -0.113834\n",
      "31          20     33         128  0.00010           2 -0.010768 -0.129218\n",
      "8           16     33          64  0.00001           1 -0.012782 -0.153388\n",
      "0           16     30          64  0.00001           1 -0.014419 -0.173029\n",
      "24          20     33          64  0.00001           1 -0.014689 -0.176269\n",
      "16          20     30          64  0.00001           1 -0.020236 -0.242832\n",
      "19          20     30          64  0.00010           2 -0.027787 -0.333447\n",
      "17          20     30          64  0.00001           2 -0.028184 -0.338206\n",
      "27          20     33          64  0.00010           2 -0.029094 -0.349133\n",
      "25          20     33          64  0.00001           2 -0.031336 -0.376031\n",
      "1           16     30          64  0.00001           2 -0.032343 -0.388121\n",
      "3           16     30          64  0.00010           2 -0.032711 -0.392531\n",
      "11          16     33          64  0.00010           2 -0.033754 -0.405052\n",
      "9           16     33          64  0.00001           2 -0.035921 -0.431049\n"
     ]
    }
   ],
   "source": [
    "# LSTM Grid Search (Extended: all hyperparameters tunable)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import itertools\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Set seed function\n",
    "# -----------------------------\n",
    "MAIN_SEED = 2025\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load and preprocess data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"final_train_data.csv\")\n",
    "df_ret_original = df.iloc[:, 1:20]\n",
    "df_out = df.iloc[:, 21:40]\n",
    "df_m = df.iloc[:, 41:60]\n",
    "df_selected = df_m.copy()\n",
    "\n",
    "train_split_idx = int(df_selected.shape[0] * 0.8)\n",
    "val_split_idx = int(df_selected.shape[0] * 0.9)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_selected.iloc[:train_split_idx])\n",
    "X_test_scaled = scaler.transform(df_selected.iloc[val_split_idx:])\n",
    "df_y_train = df_out.iloc[:train_split_idx]\n",
    "df_y_test = df_out.iloc[val_split_idx:]\n",
    "\n",
    "def create_lstm_dataset(df, sequence_length=12, step=20):\n",
    "    X, y = [], []\n",
    "    for i in range((sequence_length - 1) * step, len(df)):\n",
    "        x_i = []\n",
    "        for j in range(sequence_length):\n",
    "            index = i - (sequence_length - 1 - j) * step\n",
    "            if index < 0:\n",
    "                break\n",
    "            x_i.append(df[index, :19])\n",
    "        if len(x_i) == sequence_length:\n",
    "            X.append(np.array(x_i))\n",
    "            y.append(df[i, 19:])\n",
    "    return torch.tensor(np.array(X), dtype=torch.float32), torch.tensor(np.array(y), dtype=torch.float32)\n",
    "\n",
    "df_selected_aug_train = np.hstack([X_train_scaled, df_y_train])\n",
    "df_selected_aug_test = np.hstack([X_test_scaled, df_y_test])\n",
    "X_train, y_train = create_lstm_dataset(df_selected_aug_train)\n",
    "X_test, y_test = create_lstm_dataset(df_selected_aug_test)\n",
    "df_ret_org_test = df_ret_original.iloc[220:, :].iloc[val_split_idx:, :]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. LSTM model definition\n",
    "# -----------------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return self.softmax(out)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Transformation for top/bottom 4\n",
    "# -----------------------------\n",
    "def transform_array(arr):\n",
    "    result = np.zeros_like(arr)\n",
    "    sorted_indices = np.argsort(arr, axis=1)\n",
    "    lowest_indices = sorted_indices[:, :4]\n",
    "    highest_indices = sorted_indices[:, -4:]\n",
    "    np.put_along_axis(result, lowest_indices, -1, axis=1)\n",
    "    np.put_along_axis(result, highest_indices, 1, axis=1)\n",
    "    return result\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Extended Grid Search\n",
    "# -----------------------------\n",
    "batch_sizes = [16, 20]\n",
    "epochs = [30, 33]\n",
    "hidden_dims = [64, 128]\n",
    "learning_rates = [0.00001, 0.0001]\n",
    "num_layers_list = [1, 2]\n",
    "\n",
    "param_grid = list(itertools.product(batch_sizes, epochs, hidden_dims, learning_rates, num_layers_list))\n",
    "\n",
    "results = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for batch_size, epoch, hidden_dim, lr, num_layers in param_grid:\n",
    "    print(f\"Running BS={batch_size}, EP={epoch}, HD={hidden_dim}, LR={lr}, NL={num_layers}\")\n",
    "    set_seed(MAIN_SEED)\n",
    "\n",
    "    model = LSTMModel(input_dim=df_selected.shape[1], hidden_dim=hidden_dim, output_dim=19, num_layers=num_layers).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            output_list.append(outputs.cpu().numpy())\n",
    "\n",
    "    y_pred = np.vstack(output_list)\n",
    "    y_pos_pred = transform_array(y_pred)\n",
    "    signals = pd.DataFrame(y_pos_pred)\n",
    "    signals.columns = df_ret_org_test.columns\n",
    "    signals.index = df_ret_org_test.index\n",
    "\n",
    "    strat_returns = (signals.shift(1) * df_ret_org_test)\n",
    "    strat_returns[\"Portfolio\"] = strat_returns.sum(axis=1) / 4\n",
    "    monthly_ret = strat_returns[\"Portfolio\"].mean()\n",
    "    annual_ret = monthly_ret * 12\n",
    "\n",
    "    results.append({\n",
    "        \"BATCH_SIZE\": batch_size,\n",
    "        \"EPOCH\": epoch,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"LR\": lr,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"Monthly\": round(monthly_ret, 6),\n",
    "        \"Annual\": round(annual_ret, 6)\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Save and print results\n",
    "# -----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nExtended Grid Search Results:\")\n",
    "print(results_df.sort_values(by=\"Annual\", ascending=False))\n",
    "results_df.to_csv(\"extended_grid_search_results3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=16, EP=33, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=30, HD=128, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=64, LR=0.0001, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=1e-05, NL=2\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=1\n",
      "Running BS=20, EP=33, HD=128, LR=0.0001, NL=2\n",
      "\n",
      "Extended Grid Search Results:\n",
      "    BATCH_SIZE  EPOCH  hidden_dim       LR  num_layers   Monthly    Annual\n",
      "24          20     33          64  0.00001           1  0.061975  0.743699\n",
      "0           16     30          64  0.00001           1  0.061615  0.739381\n",
      "8           16     33          64  0.00001           1  0.061397  0.736764\n",
      "16          20     30          64  0.00001           1  0.060110  0.721319\n",
      "20          20     30         128  0.00001           1  0.044869  0.538424\n",
      "28          20     33         128  0.00001           1  0.044850  0.538199\n",
      "4           16     30         128  0.00001           1  0.043849  0.526185\n",
      "12          16     33         128  0.00001           1  0.043406  0.520871\n",
      "21          20     30         128  0.00001           2  0.039273  0.471274\n",
      "18          20     30          64  0.00010           1  0.039078  0.468937\n",
      "26          20     33          64  0.00010           1  0.038693  0.464318\n",
      "29          20     33         128  0.00001           2  0.038538  0.462457\n",
      "5           16     30         128  0.00001           2  0.038236  0.458834\n",
      "2           16     30          64  0.00010           1  0.037247  0.446962\n",
      "13          16     33         128  0.00001           2  0.037024  0.444285\n",
      "10          16     33          64  0.00010           1  0.033032  0.396383\n",
      "25          20     33          64  0.00001           2  0.032366  0.388389\n",
      "1           16     30          64  0.00001           2  0.032065  0.384778\n",
      "9           16     33          64  0.00001           2  0.028810  0.345715\n",
      "17          20     30          64  0.00001           2  0.021928  0.263142\n",
      "22          20     30         128  0.00010           1  0.020299  0.243585\n",
      "14          16     33         128  0.00010           1  0.019070  0.228846\n",
      "6           16     30         128  0.00010           1  0.018767  0.225208\n",
      "30          20     33         128  0.00010           1  0.018731  0.224771\n",
      "23          20     30         128  0.00010           2  0.008508  0.102091\n",
      "31          20     33         128  0.00010           2  0.007619  0.091433\n",
      "7           16     30         128  0.00010           2 -0.005408 -0.064893\n",
      "15          16     33         128  0.00010           2 -0.005732 -0.068782\n",
      "3           16     30          64  0.00010           2 -0.007077 -0.084925\n",
      "27          20     33          64  0.00010           2 -0.007424 -0.089084\n",
      "19          20     30          64  0.00010           2 -0.007968 -0.095616\n",
      "11          16     33          64  0.00010           2 -0.008165 -0.097977\n"
     ]
    }
   ],
   "source": [
    "# LSTM Grid Search (Extended: all hyperparameters tunable)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import itertools\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Set seed function\n",
    "# -----------------------------\n",
    "MAIN_SEED = 88\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load and preprocess data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"final_train_data.csv\")\n",
    "df_ret_original = df.iloc[:, 1:20]\n",
    "df_out = df.iloc[:, 21:40]\n",
    "df_m = df.iloc[:, 41:60]\n",
    "df_selected = df_m.copy()\n",
    "\n",
    "train_split_idx = int(df_selected.shape[0] * 0.8)\n",
    "val_split_idx = int(df_selected.shape[0] * 0.9)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_selected.iloc[:train_split_idx])\n",
    "X_test_scaled = scaler.transform(df_selected.iloc[val_split_idx:])\n",
    "df_y_train = df_out.iloc[:train_split_idx]\n",
    "df_y_test = df_out.iloc[val_split_idx:]\n",
    "\n",
    "def create_lstm_dataset(df, sequence_length=12, step=20):\n",
    "    X, y = [], []\n",
    "    for i in range((sequence_length - 1) * step, len(df)):\n",
    "        x_i = []\n",
    "        for j in range(sequence_length):\n",
    "            index = i - (sequence_length - 1 - j) * step\n",
    "            if index < 0:\n",
    "                break\n",
    "            x_i.append(df[index, :19])\n",
    "        if len(x_i) == sequence_length:\n",
    "            X.append(np.array(x_i))\n",
    "            y.append(df[i, 19:])\n",
    "    return torch.tensor(np.array(X), dtype=torch.float32), torch.tensor(np.array(y), dtype=torch.float32)\n",
    "\n",
    "df_selected_aug_train = np.hstack([X_train_scaled, df_y_train])\n",
    "df_selected_aug_test = np.hstack([X_test_scaled, df_y_test])\n",
    "X_train, y_train = create_lstm_dataset(df_selected_aug_train)\n",
    "X_test, y_test = create_lstm_dataset(df_selected_aug_test)\n",
    "df_ret_org_test = df_ret_original.iloc[220:, :].iloc[val_split_idx:, :]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. LSTM model definition\n",
    "# -----------------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return self.softmax(out)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Transformation for top/bottom 4\n",
    "# -----------------------------\n",
    "def transform_array(arr):\n",
    "    result = np.zeros_like(arr)\n",
    "    sorted_indices = np.argsort(arr, axis=1)\n",
    "    lowest_indices = sorted_indices[:, :4]\n",
    "    highest_indices = sorted_indices[:, -4:]\n",
    "    np.put_along_axis(result, lowest_indices, -1, axis=1)\n",
    "    np.put_along_axis(result, highest_indices, 1, axis=1)\n",
    "    return result\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Extended Grid Search\n",
    "# -----------------------------\n",
    "batch_sizes = [16, 20]\n",
    "epochs = [30, 33]\n",
    "hidden_dims = [64, 128]\n",
    "learning_rates = [0.00001, 0.0001]\n",
    "num_layers_list = [1, 2]\n",
    "\n",
    "param_grid = list(itertools.product(batch_sizes, epochs, hidden_dims, learning_rates, num_layers_list))\n",
    "\n",
    "results = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for batch_size, epoch, hidden_dim, lr, num_layers in param_grid:\n",
    "    print(f\"Running BS={batch_size}, EP={epoch}, HD={hidden_dim}, LR={lr}, NL={num_layers}\")\n",
    "    set_seed(MAIN_SEED)\n",
    "\n",
    "    model = LSTMModel(input_dim=df_selected.shape[1], hidden_dim=hidden_dim, output_dim=19, num_layers=num_layers).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            output_list.append(outputs.cpu().numpy())\n",
    "\n",
    "    y_pred = np.vstack(output_list)\n",
    "    y_pos_pred = transform_array(y_pred)\n",
    "    signals = pd.DataFrame(y_pos_pred)\n",
    "    signals.columns = df_ret_org_test.columns\n",
    "    signals.index = df_ret_org_test.index\n",
    "\n",
    "    strat_returns = (signals.shift(1) * df_ret_org_test)\n",
    "    strat_returns[\"Portfolio\"] = strat_returns.sum(axis=1) / 4\n",
    "    monthly_ret = strat_returns[\"Portfolio\"].mean()\n",
    "    annual_ret = monthly_ret * 12\n",
    "\n",
    "    results.append({\n",
    "        \"BATCH_SIZE\": batch_size,\n",
    "        \"EPOCH\": epoch,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"LR\": lr,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"Monthly\": round(monthly_ret, 6),\n",
    "        \"Annual\": round(annual_ret, 6)\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Save and print results\n",
    "# -----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nExtended Grid Search Results:\")\n",
    "print(results_df.sort_values(by=\"Annual\", ascending=False))\n",
    "results_df.to_csv(\"extended_grid_search_results4.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
